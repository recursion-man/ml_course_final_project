{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from models.mnist_autoencoder import MNISTAutoencoder\n",
    "from trainers.autoencoder_trainer import AutoencoderTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import models.mnist_autoencoder\n",
    "import trainers.autoencoder_trainer\n",
    "# importlib.reload(models.mnist_autoencoder)  \n",
    "# importlib.reload(trainers.autoencoder_trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "train_dataset = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
    "val_dataset   = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "single_image = images[0]  \n",
    "single_label = labels[0]  \n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(single_image.squeeze(0), cmap=\"gray\")  \n",
    "plt.title(f\"Label: {single_label.item()}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTAutoencoder(\n",
      "  (encoder): Encoder(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "    (fc): Linear(in_features=3136, out_features=128, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (fc): Linear(in_features=128, out_features=3136, bias=True)\n",
      "    (deconv): Sequential(\n",
      "      (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): ConvTranspose2d(32, 1, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    )\n",
      "    (out_activation): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "autoencoder = MNISTAutoencoder(latent_dim=128)\n",
    "print(autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] - Train Loss: 0.0138\n",
      "Epoch [1] - Val   Loss: 0.0032\n",
      "Checkpoint saved to autoencoder_checkpoint.pth\n",
      "Epoch [2] - Train Loss: 0.0026\n",
      "Epoch [2] - Val   Loss: 0.0021\n",
      "Checkpoint saved to autoencoder_checkpoint.pth\n",
      "Epoch [3] - Train Loss: 0.0019\n",
      "Epoch [3] - Val   Loss: 0.0017\n",
      "Checkpoint saved to autoencoder_checkpoint.pth\n",
      "Epoch [4] - Train Loss: 0.0016\n",
      "Epoch [4] - Val   Loss: 0.0015\n",
      "Checkpoint saved to autoencoder_checkpoint.pth\n",
      "Epoch [5] - Train Loss: 0.0014\n",
      "Epoch [5] - Val   Loss: 0.0013\n",
      "Checkpoint saved to autoencoder_checkpoint.pth\n",
      "Epoch [6] - Train Loss: 0.0013\n",
      "Epoch [6] - Val   Loss: 0.0012\n",
      "Checkpoint saved to autoencoder_checkpoint.pth\n",
      "Epoch [7] - Train Loss: 0.0012\n",
      "Epoch [7] - Val   Loss: 0.0011\n",
      "Checkpoint saved to autoencoder_checkpoint.pth\n",
      "Epoch [8] - Train Loss: 0.0011\n",
      "Epoch [8] - Val   Loss: 0.0011\n",
      "Checkpoint saved to autoencoder_checkpoint.pth\n",
      "Epoch [9] - Train Loss: 0.0010\n",
      "Epoch [9] - Val   Loss: 0.0011\n",
      "Checkpoint saved to autoencoder_checkpoint.pth\n",
      "Epoch [10] - Train Loss: 0.0010\n",
      "Epoch [10] - Val   Loss: 0.0010\n",
      "Checkpoint saved to autoencoder_checkpoint.pth\n"
     ]
    }
   ],
   "source": [
    "trainer = AutoencoderTrainer(\n",
    "    model=autoencoder,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device='cuda',\n",
    "    lr=1e-3,\n",
    "    num_epochs=10,\n",
    "    save_path='autoencoder_checkpoint.pth',\n",
    "    resume_path=None  # start from scratch\n",
    ")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from checkpoint: autoencoder_checkpoint.pth\n",
      "Resumed at epoch 11\n",
      "Epoch [11] - Train Loss: 0.0010\n",
      "Epoch [11] - Val   Loss: 0.0010\n",
      "Checkpoint saved to autoencoder_checkpoint.pth\n",
      "Epoch [12] - Train Loss: 0.0009\n",
      "Epoch [12] - Val   Loss: 0.0009\n",
      "Checkpoint saved to autoencoder_checkpoint.pth\n",
      "Epoch [13] - Train Loss: 0.0009\n",
      "Epoch [13] - Val   Loss: 0.0009\n",
      "Checkpoint saved to autoencoder_checkpoint.pth\n",
      "Epoch [14] - Train Loss: 0.0009\n",
      "Epoch [14] - Val   Loss: 0.0009\n",
      "Checkpoint saved to autoencoder_checkpoint.pth\n",
      "Epoch [15] - Train Loss: 0.0008\n",
      "Epoch [15] - Val   Loss: 0.0009\n",
      "Checkpoint saved to autoencoder_checkpoint.pth\n",
      "Epoch [16] - Train Loss: 0.0008\n",
      "Epoch [16] - Val   Loss: 0.0009\n",
      "Checkpoint saved to autoencoder_checkpoint.pth\n",
      "Epoch [17] - Train Loss: 0.0008\n",
      "Epoch [17] - Val   Loss: 0.0009\n",
      "Checkpoint saved to autoencoder_checkpoint.pth\n",
      "Epoch [18] - Train Loss: 0.0008\n",
      "Epoch [18] - Val   Loss: 0.0009\n",
      "Checkpoint saved to autoencoder_checkpoint.pth\n",
      "Epoch [19] - Train Loss: 0.0008\n",
      "Epoch [19] - Val   Loss: 0.0008\n",
      "Checkpoint saved to autoencoder_checkpoint.pth\n",
      "Epoch [20] - Train Loss: 0.0008\n",
      "Epoch [20] - Val   Loss: 0.0008\n",
      "Checkpoint saved to autoencoder_checkpoint.pth\n"
     ]
    }
   ],
   "source": [
    "autoencoder_2 = MNISTAutoencoder(latent_dim=128)\n",
    "\n",
    "trainer2 = AutoencoderTrainer(\n",
    "    model=autoencoder_2,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device='cuda',\n",
    "    lr=1e-3,\n",
    "    num_epochs=10,                      # train 10 more epochs\n",
    "    save_path='autoencoder_checkpoint.pth',\n",
    "    resume_path='autoencoder_checkpoint.pth'  # resume from the last checkpoint\n",
    ")\n",
    "trainer2.train()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.mnist_calssifier import MNISTClassifier\n",
    "from trainers.classifier_trainer import ClassifierTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MNISTClassifier(latent_dim=128, num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTClassifier(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] - Train Loss: 0.3913, Train Acc: 0.8937\n",
      "Epoch [1] - Val   Loss: 0.1992, Val   Acc: 0.9413\n",
      "Checkpoint saved to classifier_checkpoint.pth\n",
      "Epoch [2] - Train Loss: 0.1724, Train Acc: 0.9506\n",
      "Epoch [2] - Val   Loss: 0.1417, Val   Acc: 0.9581\n",
      "Checkpoint saved to classifier_checkpoint.pth\n",
      "Epoch [3] - Train Loss: 0.1250, Train Acc: 0.9642\n",
      "Epoch [3] - Val   Loss: 0.1123, Val   Acc: 0.9662\n",
      "Checkpoint saved to classifier_checkpoint.pth\n",
      "Epoch [4] - Train Loss: 0.0977, Train Acc: 0.9721\n",
      "Epoch [4] - Val   Loss: 0.1008, Val   Acc: 0.9701\n",
      "Checkpoint saved to classifier_checkpoint.pth\n",
      "Epoch [5] - Train Loss: 0.0807, Train Acc: 0.9766\n",
      "Epoch [5] - Val   Loss: 0.0884, Val   Acc: 0.9729\n",
      "Checkpoint saved to classifier_checkpoint.pth\n",
      "Epoch [6] - Train Loss: 0.0685, Train Acc: 0.9805\n",
      "Epoch [6] - Val   Loss: 0.0861, Val   Acc: 0.9736\n",
      "Checkpoint saved to classifier_checkpoint.pth\n",
      "Epoch [7] - Train Loss: 0.0594, Train Acc: 0.9824\n",
      "Epoch [7] - Val   Loss: 0.0828, Val   Acc: 0.9734\n",
      "Checkpoint saved to classifier_checkpoint.pth\n",
      "Epoch [8] - Train Loss: 0.0525, Train Acc: 0.9847\n",
      "Epoch [8] - Val   Loss: 0.0804, Val   Acc: 0.9736\n",
      "Checkpoint saved to classifier_checkpoint.pth\n",
      "Epoch [9] - Train Loss: 0.0465, Train Acc: 0.9869\n",
      "Epoch [9] - Val   Loss: 0.0797, Val   Acc: 0.9754\n",
      "Checkpoint saved to classifier_checkpoint.pth\n",
      "Epoch [10] - Train Loss: 0.0414, Train Acc: 0.9879\n",
      "Epoch [10] - Val   Loss: 0.0789, Val   Acc: 0.9763\n",
      "Checkpoint saved to classifier_checkpoint.pth\n"
     ]
    }
   ],
   "source": [
    "trainer = ClassifierTrainer(\n",
    "    encoder=autoencoder_2.encoder,\n",
    "    classifier=classifier,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=10,\n",
    "    save_path='classifier_checkpoint.pth'\n",
    ")\n",
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from checkpoint: classifier_checkpoint.pth\n",
      "Resumed at epoch 11\n",
      "Epoch [11] - Train Loss: 0.0366, Train Acc: 0.9893\n",
      "Epoch [11] - Val   Loss: 0.0828, Val   Acc: 0.9747\n",
      "Checkpoint saved to classifier_checkpoint.pth\n",
      "Epoch [12] - Train Loss: 0.0333, Train Acc: 0.9900\n",
      "Epoch [12] - Val   Loss: 0.0842, Val   Acc: 0.9746\n",
      "Checkpoint saved to classifier_checkpoint.pth\n",
      "Epoch [13] - Train Loss: 0.0302, Train Acc: 0.9911\n",
      "Epoch [13] - Val   Loss: 0.0825, Val   Acc: 0.9765\n",
      "Checkpoint saved to classifier_checkpoint.pth\n",
      "Epoch [14] - Train Loss: 0.0273, Train Acc: 0.9918\n",
      "Epoch [14] - Val   Loss: 0.0856, Val   Acc: 0.9757\n",
      "Checkpoint saved to classifier_checkpoint.pth\n",
      "Epoch [15] - Train Loss: 0.0243, Train Acc: 0.9927\n",
      "Epoch [15] - Val   Loss: 0.0888, Val   Acc: 0.9749\n",
      "Checkpoint saved to classifier_checkpoint.pth\n",
      "Epoch [16] - Train Loss: 0.0226, Train Acc: 0.9936\n",
      "Epoch [16] - Val   Loss: 0.0911, Val   Acc: 0.9754\n",
      "Checkpoint saved to classifier_checkpoint.pth\n",
      "Epoch [17] - Train Loss: 0.0202, Train Acc: 0.9944\n",
      "Epoch [17] - Val   Loss: 0.0888, Val   Acc: 0.9754\n",
      "Checkpoint saved to classifier_checkpoint.pth\n",
      "Epoch [18] - Train Loss: 0.0184, Train Acc: 0.9951\n",
      "Epoch [18] - Val   Loss: 0.0883, Val   Acc: 0.9759\n",
      "Checkpoint saved to classifier_checkpoint.pth\n",
      "Epoch [19] - Train Loss: 0.0168, Train Acc: 0.9952\n",
      "Epoch [19] - Val   Loss: 0.0930, Val   Acc: 0.9748\n",
      "Checkpoint saved to classifier_checkpoint.pth\n",
      "Epoch [20] - Train Loss: 0.0151, Train Acc: 0.9963\n",
      "Epoch [20] - Val   Loss: 0.0951, Val   Acc: 0.9746\n",
      "Checkpoint saved to classifier_checkpoint.pth\n"
     ]
    }
   ],
   "source": [
    "# Tried to train the classifier for 10 more epochs\n",
    "# but it seems that the classifier is already trained \n",
    "# and any further training mosly causes overfitting\n",
    "\n",
    "trainer2 = ClassifierTrainer(\n",
    "    encoder=autoencoder_2.encoder,\n",
    "    classifier=classifier,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=10,                           # do 5 more epochs\n",
    "    save_path='classifier_checkpoint.pth',\n",
    "    resume_path='classifier_checkpoint.pth' # resume from last checkpoint\n",
    ")\n",
    "trainer2.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
