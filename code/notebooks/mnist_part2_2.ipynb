{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from models.mnist_encoder_classifier import MNISTEncoderClassifier\n",
    "from trainers.encoder_classifier_trainer import EncoderClassifierTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.mnist_encoder_classifier import MNISTEncoderClassifier\n",
    "from trainers.encoder_classifier_trainer import EncoderClassifierTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/datasets/cv_datasets/data\"\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "val_transform = transforms.ToTensor()\n",
    "\n",
    "train_dataset = datasets.MNIST(root=data_path, train=True, download=False, transform=train_transform)\n",
    "val_dataset   = datasets.MNIST(root=data_path, train=False, download=False, transform=val_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTEncoderClassifier(\n",
      "  (encoder): Encoder(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout2d(p=0.2, inplace=False)\n",
      "      (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Dropout2d(p=0.2, inplace=False)\n",
      "    )\n",
      "    (fc): Linear(in_features=3136, out_features=128, bias=True)\n",
      "  )\n",
      "  (classifier): MNISTClassifier(\n",
      "    (net): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=64, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MNISTEncoderClassifier(\n",
    "    input_shape=(1,28,28),\n",
    "    channels=[32,64],\n",
    "    kernel_sizes=[3,3],\n",
    "    strides=[2,2],\n",
    "    paddings=[1,1],\n",
    "    latent_dim=128,\n",
    "    dropout_conv=0.2,\n",
    "    dropout_fc=0.5,\n",
    "    num_classes=10\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = EncoderClassifierTrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    lr=1e-3,\n",
    "    num_epochs=15,\n",
    "    save_path='mnist_part2_2_checkpoint.pth',\n",
    "    resume_path=None,\n",
    "    weight_decay=1e-4,\n",
    "    early_stopping=True,\n",
    "    patience=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] - Train Loss: 0.5721, Train Acc: 0.8191\n",
      "Epoch [1] - Val   Loss: 0.0955, Val   Acc: 0.9683\n",
      "Epoch [2] - Train Loss: 0.3402, Train Acc: 0.8975\n",
      "Epoch [2] - Val   Loss: 0.0705, Val   Acc: 0.9771\n",
      "Epoch [3] - Train Loss: 0.2901, Train Acc: 0.9121\n",
      "Epoch [3] - Val   Loss: 0.0623, Val   Acc: 0.9783\n",
      "Epoch [4] - Train Loss: 0.2574, Train Acc: 0.9224\n",
      "Epoch [4] - Val   Loss: 0.0576, Val   Acc: 0.9791\n",
      "Epoch [5] - Train Loss: 0.2433, Train Acc: 0.9269\n",
      "Epoch [5] - Val   Loss: 0.0517, Val   Acc: 0.9809\n",
      "Epoch [6] - Train Loss: 0.2281, Train Acc: 0.9305\n",
      "Epoch [6] - Val   Loss: 0.0466, Val   Acc: 0.9834\n",
      "Epoch [7] - Train Loss: 0.2182, Train Acc: 0.9348\n",
      "Epoch [7] - Val   Loss: 0.0408, Val   Acc: 0.9854\n",
      "Epoch [8] - Train Loss: 0.2143, Train Acc: 0.9368\n",
      "Epoch [8] - Val   Loss: 0.0393, Val   Acc: 0.9873\n",
      "Epoch [9] - Train Loss: 0.2018, Train Acc: 0.9402\n",
      "Epoch [9] - Val   Loss: 0.0484, Val   Acc: 0.9829\n",
      "Epoch [10] - Train Loss: 0.2017, Train Acc: 0.9406\n",
      "Epoch [10] - Val   Loss: 0.0358, Val   Acc: 0.9884\n",
      "Epoch [11] - Train Loss: 0.1968, Train Acc: 0.9418\n",
      "Epoch [11] - Val   Loss: 0.0369, Val   Acc: 0.9860\n",
      "Epoch [12] - Train Loss: 0.1853, Train Acc: 0.9457\n",
      "Epoch [12] - Val   Loss: 0.0376, Val   Acc: 0.9868\n",
      "Epoch [13] - Train Loss: 0.1870, Train Acc: 0.9446\n",
      "Epoch [13] - Val   Loss: 0.0398, Val   Acc: 0.9863\n",
      "Early stopping triggered at epoch 13\n",
      "Classification training complete.\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] - Train Loss: 0.7070, Train Acc: 0.7719\n",
      "Epoch [1] - Val   Loss: 0.1155, Val   Acc: 0.9629\n",
      "Epoch [2] - Train Loss: 0.3647, Train Acc: 0.8922\n",
      "Epoch [2] - Val   Loss: 0.0772, Val   Acc: 0.9763\n",
      "Epoch [3] - Train Loss: 0.3074, Train Acc: 0.9098\n",
      "Epoch [3] - Val   Loss: 0.0658, Val   Acc: 0.9789\n",
      "Epoch [4] - Train Loss: 0.2816, Train Acc: 0.9172\n",
      "Epoch [4] - Val   Loss: 0.0525, Val   Acc: 0.9825\n",
      "Epoch [5] - Train Loss: 0.2569, Train Acc: 0.9251\n",
      "Epoch [5] - Val   Loss: 0.0519, Val   Acc: 0.9820\n",
      "Epoch [6] - Train Loss: 0.2470, Train Acc: 0.9271\n",
      "Epoch [6] - Val   Loss: 0.0465, Val   Acc: 0.9843\n",
      "Epoch [7] - Train Loss: 0.2374, Train Acc: 0.9306\n",
      "Epoch [7] - Val   Loss: 0.0443, Val   Acc: 0.9841\n",
      "Epoch [8] - Train Loss: 0.2289, Train Acc: 0.9331\n",
      "Epoch [8] - Val   Loss: 0.0401, Val   Acc: 0.9875\n",
      "Epoch [9] - Train Loss: 0.2200, Train Acc: 0.9344\n",
      "Epoch [9] - Val   Loss: 0.0425, Val   Acc: 0.9862\n",
      "Epoch [10] - Train Loss: 0.2143, Train Acc: 0.9373\n",
      "Epoch [10] - Val   Loss: 0.0409, Val   Acc: 0.9864\n",
      "Epoch [11] - Train Loss: 0.2110, Train Acc: 0.9385\n",
      "Epoch [11] - Val   Loss: 0.0396, Val   Acc: 0.9867\n",
      "Epoch [12] - Train Loss: 0.2044, Train Acc: 0.9409\n",
      "Epoch [12] - Val   Loss: 0.0354, Val   Acc: 0.9879\n",
      "Epoch [13] - Train Loss: 0.2013, Train Acc: 0.9404\n",
      "Epoch [13] - Val   Loss: 0.0397, Val   Acc: 0.9852\n",
      "Epoch [14] - Train Loss: 0.1950, Train Acc: 0.9425\n",
      "Epoch [14] - Val   Loss: 0.0351, Val   Acc: 0.9890\n",
      "Epoch [15] - Train Loss: 0.1920, Train Acc: 0.9438\n",
      "Epoch [15] - Val   Loss: 0.0342, Val   Acc: 0.9880\n",
      "Classification training complete.\n"
     ]
    }
   ],
   "source": [
    "model2 = MNISTEncoderClassifier(\n",
    "    input_shape=(1,28,28),\n",
    "    channels=[32,64],\n",
    "    kernel_sizes=[3,3],\n",
    "    strides=[2,2],\n",
    "    paddings=[1,1],\n",
    "    latent_dim=128,\n",
    "    dropout_conv=0.2,\n",
    "    dropout_fc=0.5,\n",
    "    num_classes=10\n",
    ")\n",
    "trainer = EncoderClassifierTrainer(\n",
    "    model=model2,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    lr=1e-3,\n",
    "    num_epochs=15,\n",
    "    save_path='mnist_part2_2_co_conv_drop_checkpoint.pth',\n",
    "    resume_path=None,\n",
    "    weight_decay=1e-4,\n",
    "    early_stopping=True,\n",
    "    patience=3\n",
    ")\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
