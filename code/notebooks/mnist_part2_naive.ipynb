{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Here I tried the naive approach without dropouts, data augmentation, weight decay, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from models.mnist_encoder_classifier import MNISTEncoderClassifier\n",
    "from trainers.encoder_classifier_trainer import EncoderClassifierTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.mnist_encoder_classifier import MNISTEncoderClassifier\n",
    "from trainers.encoder_classifier_trainer import EncoderClassifierTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/datasets/cv_datasets/data\"\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.MNIST(root=data_path, train=True, download=False, transform=transform)\n",
    "val_dataset   = datasets.MNIST(root=data_path, train=False, download=False, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTEncoderClassifier(\n",
      "  (encoder): Encoder(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "    (fc): Linear(in_features=3136, out_features=128, bias=True)\n",
      "  )\n",
      "  (classifier): MNISTClassifier(\n",
      "    (net): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MNISTEncoderClassifier(latent_dim=128, num_classes=10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = EncoderClassifierTrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    lr=1e-3,\n",
    "    num_epochs=5,\n",
    "    save_path='mnist_encoder_classifier_checkpoint.pth',\n",
    "    resume_path=None  # or 'mnist_encoder_classifier_checkpoint.pth' to resume\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] - Train Loss: 0.2329, Train Acc: 0.9296\n",
      "Epoch [1] - Val   Loss: 0.0729, Val   Acc: 0.9762\n",
      "Checkpoint saved to mnist_encoder_classifier_checkpoint.pth\n",
      "Epoch [2] - Train Loss: 0.0683, Train Acc: 0.9788\n",
      "Epoch [2] - Val   Loss: 0.0623, Val   Acc: 0.9794\n",
      "Checkpoint saved to mnist_encoder_classifier_checkpoint.pth\n",
      "Epoch [3] - Train Loss: 0.0485, Train Acc: 0.9844\n",
      "Epoch [3] - Val   Loss: 0.0476, Val   Acc: 0.9844\n",
      "Checkpoint saved to mnist_encoder_classifier_checkpoint.pth\n",
      "Epoch [4] - Train Loss: 0.0377, Train Acc: 0.9879\n",
      "Epoch [4] - Val   Loss: 0.0453, Val   Acc: 0.9850\n",
      "Checkpoint saved to mnist_encoder_classifier_checkpoint.pth\n",
      "Epoch [5] - Train Loss: 0.0302, Train Acc: 0.9900\n",
      "Epoch [5] - Val   Loss: 0.0463, Val   Acc: 0.9844\n",
      "Checkpoint saved to mnist_encoder_classifier_checkpoint.pth\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from checkpoint mnist_encoder_classifier_checkpoint.pth\n",
      "Resumed at epoch 6\n",
      "Epoch [6] - Train Loss: 0.0251, Train Acc: 0.9918\n",
      "Epoch [6] - Val   Loss: 0.0470, Val   Acc: 0.9851\n",
      "Checkpoint saved to mnist_encoder_classifier_after_10_epochs_checkpoint.pth\n",
      "Epoch [7] - Train Loss: 0.0191, Train Acc: 0.9935\n",
      "Epoch [7] - Val   Loss: 0.0770, Val   Acc: 0.9800\n",
      "Checkpoint saved to mnist_encoder_classifier_after_10_epochs_checkpoint.pth\n",
      "Epoch [8] - Train Loss: 0.0172, Train Acc: 0.9944\n",
      "Epoch [8] - Val   Loss: 0.0409, Val   Acc: 0.9887\n",
      "Checkpoint saved to mnist_encoder_classifier_after_10_epochs_checkpoint.pth\n",
      "Epoch [9] - Train Loss: 0.0155, Train Acc: 0.9948\n",
      "Epoch [9] - Val   Loss: 0.0484, Val   Acc: 0.9871\n",
      "Checkpoint saved to mnist_encoder_classifier_after_10_epochs_checkpoint.pth\n",
      "Epoch [10] - Train Loss: 0.0145, Train Acc: 0.9948\n",
      "Epoch [10] - Val   Loss: 0.0504, Val   Acc: 0.9868\n",
      "Checkpoint saved to mnist_encoder_classifier_after_10_epochs_checkpoint.pth\n"
     ]
    }
   ],
   "source": [
    "model2 = MNISTEncoderClassifier(latent_dim=128, num_classes=10)\n",
    "trainer = EncoderClassifierTrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    lr=1e-3,\n",
    "    num_epochs=5,\n",
    "    save_path='mnist_encoder_classifier_after_10_epochs_checkpoint.pth',\n",
    "    resume_path='mnist_encoder_classifier_checkpoint.pth' \n",
    "    )\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from checkpoint mnist_encoder_classifier_after_10_epochs_checkpoint.pth\n",
      "Resumed at epoch 11\n",
      "Epoch [11] - Train Loss: 0.0111, Train Acc: 0.9961\n",
      "Epoch [11] - Val   Loss: 0.0478, Val   Acc: 0.9891\n",
      "Checkpoint saved to mnist_encoder_classifier_after_15_epochs_checkpoint.pth\n",
      "Epoch [12] - Train Loss: 0.0094, Train Acc: 0.9970\n",
      "Epoch [12] - Val   Loss: 0.0593, Val   Acc: 0.9862\n",
      "Checkpoint saved to mnist_encoder_classifier_after_15_epochs_checkpoint.pth\n",
      "Epoch [13] - Train Loss: 0.0100, Train Acc: 0.9966\n",
      "Epoch [13] - Val   Loss: 0.0600, Val   Acc: 0.9861\n",
      "Checkpoint saved to mnist_encoder_classifier_after_15_epochs_checkpoint.pth\n",
      "Epoch [14] - Train Loss: 0.0088, Train Acc: 0.9970\n",
      "Epoch [14] - Val   Loss: 0.0539, Val   Acc: 0.9879\n",
      "Checkpoint saved to mnist_encoder_classifier_after_15_epochs_checkpoint.pth\n",
      "Epoch [15] - Train Loss: 0.0101, Train Acc: 0.9967\n",
      "Epoch [15] - Val   Loss: 0.0582, Val   Acc: 0.9876\n",
      "Checkpoint saved to mnist_encoder_classifier_after_15_epochs_checkpoint.pth\n"
     ]
    }
   ],
   "source": [
    "model3 = MNISTEncoderClassifier(latent_dim=128, num_classes=10)\n",
    "trainer = EncoderClassifierTrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    lr=1e-3,\n",
    "    num_epochs=5,\n",
    "    save_path='mnist_encoder_classifier_after_15_epochs_checkpoint.pth',\n",
    "    resume_path='mnist_encoder_classifier_after_10_epochs_checkpoint.pth' \n",
    "    )\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from checkpoint mnist_encoder_classifier_checkpoint.pth\n",
      "Resumed at epoch 6\n",
      "Epoch [6] - Train Loss: 0.0237, Train Acc: 0.9925\n",
      "Epoch [6] - Val   Loss: 0.0491, Val   Acc: 0.9850\n",
      "Checkpoint saved to mnist_encoder_classifier_after_8_epochs_checkpoint.pth\n",
      "Epoch [7] - Train Loss: 0.0195, Train Acc: 0.9935\n",
      "Epoch [7] - Val   Loss: 0.0540, Val   Acc: 0.9848\n",
      "Checkpoint saved to mnist_encoder_classifier_after_8_epochs_checkpoint.pth\n",
      "Epoch [8] - Train Loss: 0.0181, Train Acc: 0.9938\n",
      "Epoch [8] - Val   Loss: 0.0518, Val   Acc: 0.9852\n",
      "Checkpoint saved to mnist_encoder_classifier_after_8_epochs_checkpoint.pth\n"
     ]
    }
   ],
   "source": [
    "#  Seems that 8 epochs resulted in the best performance\n",
    "model = MNISTEncoderClassifier(latent_dim=128, num_classes=10)\n",
    "trainer = EncoderClassifierTrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    lr=1e-3,\n",
    "    num_epochs=3,\n",
    "    save_path='mnist_encoder_classifier_after_8_epochs_checkpoint.pth',\n",
    "    resume_path='mnist_encoder_classifier_checkpoint.pth' \n",
    "    )\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
