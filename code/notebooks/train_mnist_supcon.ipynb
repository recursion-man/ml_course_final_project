{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from models.common_autoencoder_blocks import Encoder  \n",
    "from models.mnist_supconv import MNISTSupCon\n",
    "from trainers.supcon_trainer import SupConTrainer\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoCropsTransform:\n",
    "    \"\"\"\n",
    "    Given one PIL image, apply base_transform twice\n",
    "    to create two 'views' of the same image.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_transform):\n",
    "        self.base_transform = base_transform\n",
    "\n",
    "    def __call__(self, x):\n",
    "        im1 = self.base_transform(x)\n",
    "        im2 = self.base_transform(x)\n",
    "        return im1, im2\n",
    "\n",
    "base_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(28, scale=(0.8, 1.0)),  # Random crop\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), shear=5),  # Random translation\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_transform = TwoCropsTransform(base_transform)\n",
    "val_base_transform = transforms.Compose([transforms.ToTensor()])\n",
    "val_transform = TwoCropsTransform(val_base_transform)\n",
    "\n",
    "data_path = \"/datasets/cv_datasets/data\"\n",
    "train_dataset = datasets.MNIST(root=data_path, train=True, download=True, transform=train_transform)\n",
    "val_dataset   = datasets.MNIST(root=data_path, train=False, download=True, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2, drop_last=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big_batch: torch.Size([128, 1, 28, 28]), labels_rep: torch.Size([128]), batch_size: 64\n"
     ]
    }
   ],
   "source": [
    "for (im1, im2), labels in train_loader:\n",
    "    # im1, im2: shape [B, C, H, W]\n",
    "    # labels: shape [B]\n",
    "    batch_size = labels.size(0)\n",
    "    big_batch = torch.cat([im1, im2], dim=0)\n",
    "    labels_rep = torch.cat([labels, labels], dim=0)\n",
    "\n",
    "    print (f\"big_batch: {big_batch.shape}, labels_rep: {labels_rep.shape}, batch_size: {batch_size}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = MNISTSupCon(\n",
    "    input_shape=(1,28,28),\n",
    "    channels=[32,64],\n",
    "    kernel_sizes=[3,3],\n",
    "    strides=[2,2],\n",
    "    paddings=[1,1],\n",
    "    latent_dim=128,\n",
    "    batch_norm_conv=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTSupCon(\n",
      "  (encoder): Encoder(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Dropout2d(p=0.2, inplace=False)\n",
      "      (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Dropout2d(p=0.2, inplace=False)\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=3136, out_features=1024, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=1024, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(model)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "trainer = SupConTrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=50,\n",
    "    patience=5,\n",
    "    save_path='mnist_supcon.pth'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] Train Loss: 3.7111\n",
      "Epoch [1] Val   Loss: 2.7990\n",
      "Epoch [2] Train Loss: 2.9478\n",
      "Epoch [2] Val   Loss: 2.7230\n",
      "Epoch [3] Train Loss: 2.8712\n",
      "Epoch [3] Val   Loss: 2.6999\n",
      "Epoch [4] Train Loss: 2.8400\n",
      "Epoch [4] Val   Loss: 2.6979\n",
      "Epoch [5] Train Loss: 2.8229\n",
      "Epoch [5] Val   Loss: 2.6914\n",
      "Epoch [6] Train Loss: 2.8108\n",
      "Epoch [6] Val   Loss: 2.6918\n",
      "Epoch [7] Train Loss: 2.8045\n",
      "Epoch [7] Val   Loss: 2.6802\n",
      "Epoch [8] Train Loss: 2.8021\n",
      "Epoch [8] Val   Loss: 2.6849\n",
      "Epoch [9] Train Loss: 2.7949\n",
      "Epoch [9] Val   Loss: 2.6832\n",
      "Epoch [10] Train Loss: 2.7969\n",
      "Epoch [10] Val   Loss: 2.6814\n",
      "Epoch [11] Train Loss: 2.7865\n",
      "Epoch [11] Val   Loss: 2.6833\n",
      "Epoch [12] Train Loss: 2.7888\n",
      "Epoch [12] Val   Loss: 2.6766\n",
      "Epoch [13] Train Loss: 2.7858\n",
      "Epoch [13] Val   Loss: 2.6779\n",
      "Epoch [14] Train Loss: 2.7860\n",
      "Epoch [14] Val   Loss: 2.6758\n",
      "Epoch [15] Train Loss: 2.7832\n",
      "Epoch [15] Val   Loss: 2.6735\n",
      "Epoch [16] Train Loss: 2.7790\n",
      "Epoch [16] Val   Loss: 2.6722\n",
      "Epoch [17] Train Loss: 2.7801\n",
      "Epoch [17] Val   Loss: 2.6688\n",
      "Epoch [18] Train Loss: 2.7781\n",
      "Epoch [18] Val   Loss: 2.6715\n",
      "Epoch [19] Train Loss: 2.7787\n",
      "Epoch [19] Val   Loss: 2.6677\n",
      "Epoch [20] Train Loss: 2.7766\n",
      "Epoch [20] Val   Loss: 2.6710\n",
      "Epoch [21] Train Loss: 2.7730\n",
      "Epoch [21] Val   Loss: 2.6681\n",
      "Epoch [22] Train Loss: 2.7757\n",
      "Epoch [22] Val   Loss: 2.6732\n",
      "Epoch [23] Train Loss: 2.7715\n",
      "Epoch [23] Val   Loss: 2.6724\n",
      "Epoch [24] Train Loss: 2.7721\n",
      "Epoch [24] Val   Loss: 2.6738\n",
      "Early stopping at epoch 24, best val loss: 2.6677\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# (5) Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting linear evaluation...\n",
      "  [LinearEval] epoch 1/5, loss=2.3634\n",
      "  [LinearEval] epoch 2/5, loss=2.1465\n",
      "  [LinearEval] epoch 3/5, loss=1.9610\n",
      "  [LinearEval] epoch 4/5, loss=1.7908\n",
      "  [LinearEval] epoch 5/5, loss=1.6333\n",
      "Linear Evaluation Accuracy: 98.49%\n",
      "Classification Accuracy: 98.49%\n"
     ]
    }
   ],
   "source": [
    "#  Results after 10 epochs\n",
    "eval_transform = transforms.ToTensor()\n",
    "eval_dataset = datasets.MNIST(root=data_path, train=False, download=False, transform=eval_transform)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "acc = trainer.classify_evaluation(eval_loader, epochs=5)\n",
    "print(f'Classification Accuracy: {acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'resume_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mSupConTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../checkpoints/mnist_supcon.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../checkpoints/mnist_supcon_40_epochs.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'resume_path'"
     ]
    }
   ],
   "source": [
    "trainer = SupConTrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    num_epochs=30,\n",
    "    patience=3,\n",
    "    resume_path='../checkpoints/mnist_supcon.pth',\n",
    "    save_path='../checkpoints/mnist_supcon_40_epochs.pth'\n",
    ")\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
