{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from models.mnist_encoder_classifier import MNISTEncoderClassifier\n",
    "from trainers.encoder_classifier_trainer import EncoderClassifierTrainer\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device)) \n",
    "data_path = \"/datasets/cv_datasets/data\"\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "val_transform = transforms.ToTensor()\n",
    "\n",
    "train_dataset = datasets.MNIST(root=data_path, train=True, download=False, transform=train_transform)\n",
    "val_dataset   = datasets.MNIST(root=data_path, train=False, download=False, transform=val_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTEncoderClassifier(\n",
      "  (encoder): Encoder(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Dropout2d(p=0.2, inplace=False)\n",
      "      (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Dropout2d(p=0.2, inplace=False)\n",
      "    )\n",
      "    (fc): Linear(in_features=3136, out_features=128, bias=True)\n",
      "  )\n",
      "  (classifier): MNISTClassifier(\n",
      "    (net): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Dropout(p=0.5, inplace=False)\n",
      "      (4): Linear(in_features=64, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MNISTEncoderClassifier(\n",
    "    input_shape=(1,28,28),\n",
    "    channels=[32,64],\n",
    "    kernel_sizes=[3,3],\n",
    "    strides=[2,2],\n",
    "    paddings=[1,1],\n",
    "    latent_dim=128,\n",
    "    dropout_fc=0.5,\n",
    "    batch_norm_fc=True,\n",
    "    batch_norm_conv=True,\n",
    "    num_classes=10\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] - Train Loss: 0.6667, Train Acc: 0.8034\n",
      "Epoch [1] - Val   Loss: 0.0901, Val   Acc: 0.9763\n",
      "Epoch [2] - Train Loss: 0.3481, Train Acc: 0.8945\n",
      "Epoch [2] - Val   Loss: 0.0625, Val   Acc: 0.9801\n",
      "Epoch [3] - Train Loss: 0.2891, Train Acc: 0.9132\n",
      "Epoch [3] - Val   Loss: 0.0530, Val   Acc: 0.9829\n",
      "Epoch [4] - Train Loss: 0.2674, Train Acc: 0.9203\n",
      "Epoch [4] - Val   Loss: 0.0443, Val   Acc: 0.9860\n",
      "Epoch [5] - Train Loss: 0.2456, Train Acc: 0.9264\n",
      "Epoch [5] - Val   Loss: 0.0460, Val   Acc: 0.9848\n",
      "Epoch [6] - Train Loss: 0.2344, Train Acc: 0.9293\n",
      "Epoch [6] - Val   Loss: 0.0400, Val   Acc: 0.9882\n",
      "Epoch [7] - Train Loss: 0.2282, Train Acc: 0.9310\n",
      "Epoch [7] - Val   Loss: 0.0358, Val   Acc: 0.9875\n",
      "Epoch [8] - Train Loss: 0.2148, Train Acc: 0.9350\n",
      "Epoch [8] - Val   Loss: 0.0364, Val   Acc: 0.9871\n",
      "Epoch [9] - Train Loss: 0.2128, Train Acc: 0.9364\n",
      "Epoch [9] - Val   Loss: 0.0367, Val   Acc: 0.9872\n",
      "Epoch [10] - Train Loss: 0.2035, Train Acc: 0.9384\n",
      "Epoch [10] - Val   Loss: 0.0339, Val   Acc: 0.9887\n",
      "Epoch [11] - Train Loss: 0.2006, Train Acc: 0.9389\n",
      "Epoch [11] - Val   Loss: 0.0338, Val   Acc: 0.9882\n",
      "Epoch [12] - Train Loss: 0.1991, Train Acc: 0.9401\n",
      "Epoch [12] - Val   Loss: 0.0353, Val   Acc: 0.9876\n",
      "Epoch [13] - Train Loss: 0.1951, Train Acc: 0.9422\n",
      "Epoch [13] - Val   Loss: 0.0312, Val   Acc: 0.9898\n",
      "Epoch [14] - Train Loss: 0.1937, Train Acc: 0.9414\n",
      "Epoch [14] - Val   Loss: 0.0359, Val   Acc: 0.9888\n",
      "Epoch [15] - Train Loss: 0.1881, Train Acc: 0.9446\n",
      "Epoch [15] - Val   Loss: 0.0300, Val   Acc: 0.9896\n",
      "Classification training complete.\n"
     ]
    }
   ],
   "source": [
    "trainer = EncoderClassifierTrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    lr=1e-3,\n",
    "    num_epochs=15,\n",
    "    save_path='mnist_part2_batch_norm_checkpoint.pth',\n",
    "    resume_path=None,\n",
    "    weight_decay=1e-4,\n",
    "    early_stopping=True,\n",
    "    patience=3\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from mnist_part2_batch_norm_checkpoint.pth\n",
      "Resumed at epoch 16\n",
      "Epoch [16] - Train Loss: 0.1915, Train Acc: 0.9435\n",
      "Epoch [16] - Val   Loss: 0.0314, Val   Acc: 0.9893\n",
      "Epoch [17] - Train Loss: 0.1836, Train Acc: 0.9456\n",
      "Epoch [17] - Val   Loss: 0.0292, Val   Acc: 0.9900\n",
      "Epoch [18] - Train Loss: 0.1777, Train Acc: 0.9473\n",
      "Epoch [18] - Val   Loss: 0.0287, Val   Acc: 0.9909\n",
      "Epoch [19] - Train Loss: 0.1801, Train Acc: 0.9465\n",
      "Epoch [19] - Val   Loss: 0.0328, Val   Acc: 0.9889\n",
      "Epoch [20] - Train Loss: 0.1808, Train Acc: 0.9467\n",
      "Epoch [20] - Val   Loss: 0.0294, Val   Acc: 0.9907\n",
      "Epoch [21] - Train Loss: 0.1770, Train Acc: 0.9470\n",
      "Epoch [21] - Val   Loss: 0.0273, Val   Acc: 0.9906\n",
      "Epoch [22] - Train Loss: 0.1774, Train Acc: 0.9464\n",
      "Epoch [22] - Val   Loss: 0.0330, Val   Acc: 0.9882\n",
      "Epoch [23] - Train Loss: 0.1751, Train Acc: 0.9483\n",
      "Epoch [23] - Val   Loss: 0.0277, Val   Acc: 0.9906\n",
      "Epoch [24] - Train Loss: 0.1711, Train Acc: 0.9493\n",
      "Epoch [24] - Val   Loss: 0.0306, Val   Acc: 0.9893\n",
      "Early stopping triggered at epoch 24 \n",
      " End val loss : 0.0273\n",
      "Classification training complete.\n"
     ]
    }
   ],
   "source": [
    "trainer = EncoderClassifierTrainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    lr=1e-3,\n",
    "    num_epochs=15,\n",
    "    save_path='mnist_part2_batch_norm_30_epochs_checkpoint.pth',\n",
    "    resume_path='mnist_part2_batch_norm_checkpoint.pth',\n",
    "    weight_decay=1e-4,\n",
    "    early_stopping=True,\n",
    "    patience=3\n",
    ")\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
